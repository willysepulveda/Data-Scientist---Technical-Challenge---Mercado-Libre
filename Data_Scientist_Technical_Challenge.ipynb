{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\anaconda\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\lib\\site-packages (from xgboost) (1.16.5)\n",
      "Requirement already satisfied: scipy in c:\\anaconda\\lib\\site-packages (from xgboost) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar Paquetes\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from termcolor import colored as cl\n",
    "import itertools \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import f1_score \n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A   B        C  D  E    F    G  H  I     K  L  M  N  O  P    Q    R      S  \\\n",
      "0  0  10  50257.0  0  0  0.0  0.0  0  0  0.80  0  3  1  0  5  0.0  0.0   7.25   \n",
      "1  0  10  29014.0  0  0  0.0  0.0  0  0  0.00  0  1  1  0  3  0.0  0.0  11.66   \n",
      "2  0   7     92.0  0  1  0.0  0.0  0  1  0.00  0  3  1  0  2  0.0  0.0  86.97   \n",
      "3  9  16  50269.0  0  0  0.0  0.0  0  0  0.91  0  3  1  0  5  0.0  0.0   2.51   \n",
      "4  0   8   8180.0  0  0  0.0  0.0  0  0  0.00  0  1  1  0  1  0.0  0.0  25.96   \n",
      "\n",
      "    Monto  Fraude  \n",
      "0   37.51       1  \n",
      "1    8.18       1  \n",
      "2   13.96       1  \n",
      "3   93.67       1  \n",
      "4  135.40       1  \n"
     ]
    }
   ],
   "source": [
    "#Importando Datos\n",
    "\n",
    "df = pd.read_csv('Data_Scientist_Technical_Challenge.csv',delimiter=\",\")\n",
    "df.drop('J', axis = 1, inplace = True)\n",
    "\n",
    "df['Monto'] = pd.to_numeric(df['Monto'],errors = 'coerce')\n",
    "df['A'] = pd.to_numeric(df['A'],errors = 'coerce')\n",
    "df['B'] = pd.to_numeric(df['B'],errors = 'coerce')\n",
    "df['C'] = pd.to_numeric(df['C'],errors = 'coerce')\n",
    "df['D'] = pd.to_numeric(df['D'],errors = 'coerce')\n",
    "df['F'] = pd.to_numeric(df['F'],errors = 'coerce')\n",
    "df['G'] = pd.to_numeric(df['G'],errors = 'coerce')\n",
    "df['H'] = pd.to_numeric(df['H'],errors = 'coerce')\n",
    "df['K'] = pd.to_numeric(df['K'],errors = 'coerce')\n",
    "df['L'] = pd.to_numeric(df['L'],errors = 'coerce')\n",
    "df['M'] = pd.to_numeric(df['M'],errors = 'coerce')\n",
    "df['N'] = pd.to_numeric(df['N'],errors = 'coerce')\n",
    "df['O'] = pd.to_numeric(df['O'],errors = 'coerce')\n",
    "df['P'] = pd.to_numeric(df['P'],errors = 'coerce')\n",
    "df['Q'] = pd.to_numeric(df['Q'],errors = 'coerce')\n",
    "df['R'] = pd.to_numeric(df['R'],errors = 'coerce')\n",
    "df['S'] = pd.to_numeric(df['S'],errors = 'coerce')\n",
    "\n",
    "\n",
    "df['Monto'] = df['Monto'].replace(np.nan, 0)\n",
    "df['A'] = df['A'].replace(np.nan, 0)\n",
    "df['B'] = df['B'].replace(np.nan, 0)\n",
    "df['C'] = df['C'].replace(np.nan, 0)\n",
    "df['D'] = df['D'].replace(np.nan, 0)\n",
    "df['F'] = df['F'].replace(np.nan, 0)\n",
    "df['G'] = df['G'].replace(np.nan, 0)\n",
    "df['H'] = df['H'].replace(np.nan, 0)\n",
    "df['K'] = df['K'].replace(np.nan, 0)\n",
    "df['L'] = df['L'].replace(np.nan, 0)\n",
    "df['M'] = df['M'].replace(np.nan, 0)\n",
    "df['N'] = df['N'].replace(np.nan, 0)\n",
    "df['O'] = df['O'].replace(np.nan, 0)\n",
    "df['P'] = df['P'].replace(np.nan, 0)\n",
    "df['Q'] = df['Q'].replace(np.nan, 0)\n",
    "df['R'] = df['R'].replace(np.nan, 0)\n",
    "df['S'] = df['S'].replace(np.nan, 0)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\u001b[0m\n",
      "\u001b[1mTotal de Registros 16880\u001b[0m\n",
      "\u001b[1mTotal de Registros no Fraudelentos 12269\u001b[0m\n",
      "\u001b[1mTotal de Registros Fraudelentos 4611\u001b[0m\n",
      "\u001b[1mPorcentaje de Casos Fraudulentos 37.58\u001b[0m\n",
      "----\u001b[0m\n",
      "\u001b[1mStats Registros No-Fraudulentos\u001b[0m\n",
      "count    12269.000000\n",
      "mean         0.043291\n",
      "std          1.043126\n",
      "min         -0.862169\n",
      "25%         -0.664552\n",
      "50%         -0.345440\n",
      "75%          0.357765\n",
      "max          5.350224\n",
      "Name: Monto, dtype: float64\n",
      "----\u001b[0m\n",
      "\u001b[1mStats Registros Fraudulentos\u001b[0m\n",
      "count    4611.000000\n",
      "mean       -0.115188\n",
      "std         0.864693\n",
      "min        -0.862169\n",
      "25%        -0.653598\n",
      "50%        -0.436624\n",
      "75%         0.113405\n",
      "max         5.219081\n",
      "Name: Monto, dtype: float64\n",
      "----\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Normalización de Datos\n",
    "\n",
    "sc = StandardScaler()\n",
    "Monto = df['Monto'].values\n",
    "\n",
    "df['Monto'] = sc.fit_transform(Monto.reshape(-1, 1))\n",
    "\n",
    "#Exploración de datos\n",
    "\n",
    "# Validación Numerica\n",
    "\n",
    "Registros = len(df)\n",
    "Total_NoFraudes = len(df[df.Fraude == 0])\n",
    "Total_Fraudes = len(df[df.Fraude == 1])\n",
    "Porcentaje_Fraude = round(Total_Fraudes/Total_NoFraudes*100, 2)\n",
    "\n",
    "print(cl('----'))\n",
    "print(cl('Total de Registros {}'.format(Registros), attrs = ['bold']))\n",
    "print(cl('Total de Registros no Fraudelentos {}'.format(Total_NoFraudes), attrs = ['bold']))\n",
    "print(cl('Total de Registros Fraudelentos {}'.format(Total_Fraudes), attrs = ['bold']))\n",
    "print(cl('Porcentaje de Casos Fraudulentos {}'.format(Porcentaje_Fraude), attrs = ['bold']))\n",
    "print(cl('----'))\n",
    "\n",
    "# Descripción\n",
    "\n",
    "Registros_NoFraudulentos = df[df.Fraude == 0]\n",
    "Registros_Fraudulentos = df[df.Fraude == 1]\n",
    "\n",
    "print(cl('Stats Registros No-Fraudulentos', attrs = ['bold']))\n",
    "print(Registros_NoFraudulentos.Monto.describe())\n",
    "print(cl('----'))\n",
    "print(cl('Stats Registros Fraudulentos', attrs = ['bold']))\n",
    "print(Registros_Fraudulentos.Monto.describe())\n",
    "print(cl('----'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mX_train samples : \u001b[0m [[ 0.        6.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        1.        1.        0.\n",
      "   1.        0.        0.       21.62     -0.773724]]\n",
      "\u001b[1mX_test samples : \u001b[0m [[ 0.00000000e+00  5.00000000e+00  1.96000000e+02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.65500000e+01 -9.41705664e-02]]\n",
      "\u001b[1my_train samples : \u001b[0m [0 0 0 0 0 0 1 0 1 0]\n",
      "\u001b[1my_test samples : \u001b[0m [1 0 1 0 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Preparación de datos para modelado\n",
    "\n",
    "X = df.drop('Fraude', axis = 1).values\n",
    "y = df['Fraude'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(cl('X_train samples : ', attrs = ['bold']), X_train[:1])\n",
    "print(cl('X_test samples : ', attrs = ['bold']), X_test[0:1])\n",
    "print(cl('y_train samples : ', attrs = ['bold']), y_train[0:10])\n",
    "print(cl('y_test samples : ', attrs = ['bold']), y_test[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelado\n",
    "\n",
    "#Decision Tree\n",
    "\n",
    "tree_model = DecisionTreeClassifier(max_depth = 5)\n",
    "tree_model.fit(X_train, y_train)\n",
    "tree_yhat = tree_model.predict(X_test)\n",
    "\n",
    "#K-NN\n",
    "\n",
    "n = 5\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = n)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_yhat = knn.predict(X_test)\n",
    "\n",
    "#Logistic Regression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000,\n",
    "                        solver='lbfgs')\n",
    "lr.fit(X_train, y_train)\n",
    "lr_yhat = lr.predict(X_test)\n",
    "\n",
    "#XGBoost\n",
    "\n",
    "xgb = XGBClassifier(eval_metric='mlogloss',\n",
    "                    use_label_encoder=False)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_yhat = xgb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\u001b[0m\n",
      "\u001b[1mValidación F1 Score\u001b[0m\n",
      "----\u001b[0m\n",
      "\u001b[1mF1 score Decision Tree: 0.3315259488768396\u001b[0m\n",
      "----\u001b[0m\n",
      "\u001b[1mF1 score KNN: 0.3620338983050847\u001b[0m\n",
      "----\u001b[0m\n",
      "\u001b[1mF1 score Logistic Regression: 0.15706806282722513\u001b[0m\n",
      "----\u001b[0m\n",
      "\u001b[1mF1 score XGBoost: 0.5378151260504201\u001b[0m\n",
      "----\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Validación F1 score\n",
    "\n",
    "print(cl('----'))\n",
    "print(cl('Validación F1 Score', attrs = ['bold']))\n",
    "print(cl('----'))\n",
    "print(cl('F1 score Decision Tree: {}'.format(f1_score(y_test, tree_yhat)), attrs = ['bold']))\n",
    "print(cl('----'))\n",
    "print(cl('F1 score KNN: {}'.format(f1_score(y_test, knn_yhat)), attrs = ['bold']))\n",
    "print(cl('----'))\n",
    "print(cl('F1 score Logistic Regression: {}'.format(f1_score(y_test, lr_yhat)), attrs = ['bold']))\n",
    "print(cl('----'))\n",
    "print(cl('F1 score XGBoost: {}'.format(f1_score(y_test, xgb_yhat)), attrs = ['bold']))\n",
    "print(cl('----'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presición Decision Tree: mean:(74.5%) std:(0.8%)\n",
      "----\u001b[0m\n",
      "Presición knn: mean:(71.6%) std:(0.9%)\n",
      "----\u001b[0m\n",
      "Presición Logistic Regression: mean:(72.5%) std:(1.0%)\n",
      "----\u001b[0m\n",
      "Presición XGBoost: mean:(77.7%) std:(0.9%)\n",
      "----\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Validación Cruzada por modelo\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=5)\n",
    "\n",
    "scores = cross_val_score(tree_model, X_train, y_train, scoring='accuracy', cv=kfold, n_jobs=-1)\n",
    "print(\"Presición Decision Tree: mean:(%.1f%%) std:(%.1f%%)\" % (scores.mean()*100, scores.std()*100))\n",
    "print(cl('----'))\n",
    "scores = cross_val_score(knn, X_train, y_train, scoring='accuracy', cv=kfold, n_jobs=-1)\n",
    "print(\"Presición knn: mean:(%.1f%%) std:(%.1f%%)\" % (scores.mean()*100, scores.std()*100))\n",
    "print(cl('----'))\n",
    "scores = cross_val_score(lr, X_train, y_train, scoring='accuracy', cv=kfold, n_jobs=-1)\n",
    "print(\"Presición Logistic Regression: mean:(%.1f%%) std:(%.1f%%)\" % (scores.mean()*100, scores.std()*100))\n",
    "print(cl('----'))\n",
    "scores = cross_val_score(xgb, X_train, y_train, scoring='accuracy', cv=kfold, n_jobs=-1)\n",
    "print(\"Presición XGBoost: mean:(%.1f%%) std:(%.1f%%)\" % (scores.mean()*100, scores.std()*100))\n",
    "print(cl('----'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondab9b22ca4bed5428b85022aabe9d706ac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
